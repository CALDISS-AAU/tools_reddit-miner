{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f9231dac-e8ef-463f-a138-07f0a711e523",
   "metadata": {},
   "source": [
    "Denne notebook bruges til at hente reddit data. Den henter først kommentarer fra en subreddit, hvorefter den henter de submissions, som kommentarerne er til.\n",
    "\n",
    "Funktionerne bruger Pushshift API, så tjek at API'en er oppe: https://stats.uptimerobot.com/l8RZDu1gBG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5222588-7c11-482b-828f-0e2e6efbb676",
   "metadata": {},
   "source": [
    "Nedenstående celle bør bare kunne køres, som den er. Indlæser pakker og laver funktioner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeca9e87-23ab-49e3-ad13-03f09aeff019",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from os.path import join\n",
    "import requests\n",
    "import json\n",
    "import re\n",
    "import time\n",
    "from datetime import datetime\n",
    "import random\n",
    "\n",
    "# where to store data\n",
    "data_p = join('..', 'data')\n",
    "if not os.path.isdir(data_p):\n",
    "    os.mkdir(data_p)\n",
    "\n",
    "# pushshift endpoints\n",
    "sub_end = \"https://api.pushshift.io/reddit/search/submission/\"\n",
    "com_end = \"https://api.pushshift.io/reddit/search/comment/\"\n",
    "\n",
    "# function for comments\n",
    "def comment_get(subreddit, start, end, com_end = com_end):\n",
    "    parameters = {'subreddit': subreddit,\n",
    "                  'after': start,\n",
    "                  'before': end,\n",
    "                  'size': 499}\n",
    "    \n",
    "    r = requests.get(com_end, params = parameters)\n",
    "    \n",
    "    data = r.json().get('data')\n",
    "    \n",
    "    return(data)\n",
    "\n",
    "# function for submissions\n",
    "def submission_get(subreddit, ids, start, end, sub_end = sub_end):\n",
    "    \n",
    "    ids = ','.join(ids)\n",
    "    \n",
    "    parameters = {'subreddit': subreddit,\n",
    "                  'after': start,\n",
    "                  'before': end,\n",
    "                  'size': 499,\n",
    "                  'ids': ids}\n",
    "    \n",
    "    r = requests.get(sub_end, params = parameters)\n",
    "    \n",
    "    data = r.json().get('data')\n",
    "    \n",
    "    return(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "301c2b47-5b52-40c9-af55-9754dabf22e6",
   "metadata": {},
   "source": [
    "I nedenstående sættes indstillinger for søgning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "458271d0-6b82-475f-8ad8-dc7a36f70841",
   "metadata": {},
   "outputs": [],
   "source": [
    "# overall parameters for search\n",
    "subreddit = '' # hvilken subreddit? (udelad r/)\n",
    "#collect_start = int(datetime(2019, 2, 27, 0, 0).timestamp()) # start for indsamling\n",
    "collect_start = 1570466763\n",
    "collect_end = int(datetime(2022, 11, 1, 0, 0).timestamp()) # slut for indsamling\n",
    "\n",
    "comment_out = 'comments.json' # navn til fil med kommentarer\n",
    "submission_out = 'submissions.json' # navn til fil med opslag"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df8b787c-07e5-4592-9d9a-40fd553f0eca",
   "metadata": {},
   "source": [
    "Næste celle henter kommentarer. Den henter for 6 timer ad gangen fra `collect_start` til `collect_end`. Kommentardata gemmes i \"data\" mappen. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38516201-9dac-4d1c-9a29-7e818a400e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get comment data\n",
    "#comment_data = [] # list for storing comment data\n",
    "request_start = collect_start # setting start time of first request\n",
    "while request_start < collect_end:\n",
    "    request_end = request_start + 21600 # adding 21600 to timestamp of request_start corresponds to 6 hours\n",
    "    \n",
    "    request_data = comment_get(subreddit = subreddit, start = request_start, end = request_end) # getting data for request\n",
    "    comment_data = comment_data + request_data # adding to comment data list\n",
    "    \n",
    "    request_start = request_end + 1 # next request should start right after previous request end\n",
    "    \n",
    "    time.sleep(random.uniform(3, 4)) # wait between 3 to 4 seconds between requests\n",
    "    \n",
    "\n",
    "# save data\n",
    "data_out = join(data_p, comment_out)\n",
    "with open(data_out, 'w') as f:\n",
    "    json.dump(comment_data, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90f55e2e-d591-4da4-a1d7-b7e153b9ec11",
   "metadata": {},
   "source": [
    "Næste celle henter opslag. Den henter 450 opslag ad gangen indtil den har hentet alle submission id'er, som indgår i kommentardata. Opslagsdata gemems i \"data\" mappen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "404362ce-5cf2-4e68-ae3d-35a466ae98c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get submission ids in comment data\n",
    "subids = [entry.get('link_id') for entry in comment_data] # get submission ids for comment\n",
    "subids = list(set(subids)) # convert to set - keeping only unique ids\n",
    "subids = [link_id.replace('t3_', '') for link_id in subids] # remove prefix t3_ to get id only\n",
    "\n",
    "\n",
    "# get submission data\n",
    "submission_data = [] # list for storing submission data\n",
    "start_index = 0 # starting with first id (index 0 in list)\n",
    "while start_index <= len(subids):\n",
    "    end_index = start_index + 450 # setting index of last id of request (max 500 per request)\n",
    "    \n",
    "    if end_index >= len(subids):\n",
    "        end_index = len(subids)\n",
    "    \n",
    "    ids_get = subids[start_index:end_index]\n",
    "    \n",
    "    request_data = submission_get(subreddit = subreddit, ids = ids_get, start = collect_start, end = collect_end) # getting data for request\n",
    "    submission_data = submission_data + request_data # adding to submission data list\n",
    "    \n",
    "    start_index = end_index + 1 # next request should start with the id just after the last retrieved in the request\n",
    "    \n",
    "    time.sleep(random.uniform(3, 4)) # wait between 3 to 4 seconds between requests\n",
    "    \n",
    "\n",
    "# save data\n",
    "data_out = join(data_p, submission_out)\n",
    "with open(data_out, 'w') as f:\n",
    "    json.dump(submission_data, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
